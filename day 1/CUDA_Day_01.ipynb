{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFhsmDkhsYL0",
        "outputId": "970f93b4-c655-4ebf-d363-77a6e348971e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jun 16 21:05:29 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_addition.cu\n",
        "#include <iostream>\n",
        "\n",
        "__global__ void addVectors(const float *v1, const float *v2, float *result, int N) {\n",
        "    int index = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (index < N) {\n",
        "      result[index] = v1[index] + v2[index];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  const int N = 10;\n",
        "  float A[N], B[N], RES[N];\n",
        "\n",
        "  float *device_A, *device_B, *device_RES;\n",
        "\n",
        "  cudaMalloc(&device_A, N * sizeof(float));\n",
        "  cudaMalloc(&device_B, N * sizeof(float));\n",
        "  cudaMalloc(&device_RES, N * sizeof(float));\n",
        "\n",
        "\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    A[i] = i;\n",
        "    B[i] = i;\n",
        "  }\n",
        "\n",
        "  std::cout << \"Initialized A[0] = \" << A[0] << \", B[0] = \" << B[0] << std::endl;\n",
        "\n",
        "  cudaMemcpy(device_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(device_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "  int blockSize = 256; // 32 * 2 (must be a multiple of 32)\n",
        "  // int gridSize = ceil((float)N/blockSize);\n",
        "  int gridSize = (N + blockSize - 1) / blockSize;\n",
        "  addVectors<<<gridSize, blockSize>>>(device_A, device_B, device_RES, N);\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "\n",
        "  cudaMemcpy(RES, device_RES, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cudaFree(device_A);\n",
        "  cudaFree(device_B);\n",
        "  cudaFree(device_RES);\n",
        "\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    printf(\"%f %f %f\\n\", A[i], B[i], RES[i]);\n",
        "  }\n",
        "\n",
        "  return 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_NiChZfVifC",
        "outputId": "7664c004-3491-4c33-a4db-248ce94c475d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_addition.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !nvcc -o vector_addit vector_addition.cu\n",
        "!nvcc -o vector_addit vector_addition.cu -arch=sm_75"
      ],
      "metadata": {
        "id": "UUVQrjRytvWJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_addit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HSnFwBFvwPO",
        "outputId": "4ba71bcd-2a0b-4b7e-e3b1-799b3c57432e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized A[0] = 0, B[0] = 0\n",
            "0.000000 0.000000 0.000000\n",
            "1.000000 1.000000 2.000000\n",
            "2.000000 2.000000 4.000000\n",
            "3.000000 3.000000 6.000000\n",
            "4.000000 4.000000 8.000000\n",
            "5.000000 5.000000 10.000000\n",
            "6.000000 6.000000 12.000000\n",
            "7.000000 7.000000 14.000000\n",
            "8.000000 8.000000 16.000000\n",
            "9.000000 9.000000 18.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TnBB63rtwBTp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}